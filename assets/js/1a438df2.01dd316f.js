"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[3214],{3905:function(e,n,t){t.d(n,{Zo:function(){return d},kt:function(){return k}});var r=t(7294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,r,o=function(e,n){if(null==e)return{};var t,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var u=r.createContext({}),l=function(e){var n=r.useContext(u),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},d=function(e){var n=l(e.components);return r.createElement(u.Provider,{value:n},e.children)},p={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},c=r.forwardRef((function(e,n){var t=e.components,o=e.mdxType,a=e.originalType,u=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),c=l(t),k=o,m=c["".concat(u,".").concat(k)]||c[k]||p[k]||a;return t?r.createElement(m,i(i({ref:n},d),{},{components:t})):r.createElement(m,i({ref:n},d))}));function k(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var a=t.length,i=new Array(a);i[0]=c;var s={};for(var u in n)hasOwnProperty.call(n,u)&&(s[u]=n[u]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var l=2;l<a;l++)i[l]=t[l];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}c.displayName="MDXCreateElement"},2312:function(e,n,t){t.r(n),t.d(n,{assets:function(){return d},contentTitle:function(){return u},default:function(){return k},frontMatter:function(){return s},metadata:function(){return l},toc:function(){return p}});var r=t(3117),o=t(102),a=(t(7294),t(3905)),i=["components"],s={},u="Dokku Jupyterhub",l={unversionedId:"dokku/jupyterhub/index",id:"dokku/jupyterhub/index",title:"Dokku Jupyterhub",description:"The goal of this project is to run a dockerized jupyterhub instance on a dokku server.",source:"@site/docs/dokku/jupyterhub/index.md",sourceDirName:"dokku/jupyterhub",slug:"/dokku/jupyterhub/",permalink:"/synopsis/dokku/jupyterhub/",draft:!1,editUrl:"https://github.com/lebalz/blog/edit/main/docs/dokku/jupyterhub/index.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"GitLab",permalink:"/synopsis/dokku/gitlab"},next:{title:"Letsencrypt",permalink:"/synopsis/dokku/letsencrypt"}},d={},p=[{value:"Dokku requirements",id:"dokku-requirements",level:2},{value:"Create jupyterhub app folder",id:"create-jupyterhub-app-folder",level:2},{value:"./Dockerfile",id:"dockerfile",level:3},{value:"Images",id:"images",level:2},{value:"Option 1: Pull an existing image",id:"option-1-pull-an-existing-image",level:3},{value:"Option2: <code>./images/Dockerfile</code>",id:"option2-imagesdockerfile",level:3},{value:"Dokku Setup",id:"dokku-setup",level:2},{value:"Letsencrypt",id:"letsencrypt",level:3},{value:"Jupyterlab Settings",id:"jupyterlab-settings",level:2}],c={toc:p};function k(e){var n=e.components,t=(0,o.Z)(e,i);return(0,a.kt)("wrapper",(0,r.Z)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"dokku-jupyterhub"},"Dokku Jupyterhub"),(0,a.kt)("p",null,"The goal of this project is to run a dockerized ",(0,a.kt)("a",{parentName:"p",href:"https://jupyter.org/hub"},"jupyterhub")," instance on a ",(0,a.kt)("a",{parentName:"p",href:"https://dokku.com/"},"dokku")," server."),(0,a.kt)("p",null,"Dokku will create and handle the docker network for the communication between jupyterhub and the jupyter notebooks (spawned as separate docker containers). Dokku performs a ",(0,a.kt)("inlineCode",{parentName:"p"},"Dockerfile"),"-deploy."),(0,a.kt)("p",null,"The spawned notebook image is based on a Docker image build from the ",(0,a.kt)("inlineCode",{parentName:"p"},"images/Dockerfile")," after each deploy."),(0,a.kt)("p",null,"Data-Persistence is achieved by bind mounting directories from the dokku host to the notebook containers. See ",(0,a.kt)("inlineCode",{parentName:"p"},"jupyterhub_config.py")," for all settings."),(0,a.kt)("h2",{id:"dokku-requirements"},"Dokku requirements"),(0,a.kt)("p",null,"The following plugins are required and must be installed on your dokku host:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/lebalz/dokku-post-deploy-script"},"post-deploy-script @lebalz")," to build the users jupyterlab image after each deploy"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/dokku/dokku-postgres"},"postgres")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/dokku/dokku-letsencrypt"},"letsencrypt"))),(0,a.kt)("h2",{id:"create-jupyterhub-app-folder"},"Create jupyterhub app folder"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/lebalz/dokku-jupyterhub"},"github.com/lebalz/dokku-jupyterhub")),(0,a.kt)("p",null,"Create a new git project with the following files:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 POST_DEPLOY_SCRIPT\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 images\n\u2502   \u251c\u2500\u2500 overrides.json\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 jupyterhub_config.py\n\u2514\u2500\u2500 my_azuread.py\n")),(0,a.kt)("p",null,"There are two Dockerfiles - the one in the root is used to build the jupyterhub image, the one in the images folder is used to build the users jupyterlab image."),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"POST_DEPLOY_SCRIPT")," is used to build the users jupyterlab image after each deploy."),(0,a.kt)("p",null,"To intialize a new repository with git:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'git init\ngit add .\ngit commit -m "initial commit"\n\n# add dokku remote\ngit remote add dokku dokku@<your-ip>:jupyterhub\n')),(0,a.kt)("h3",{id:"dockerfile"},"./Dockerfile"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-docker"},'# Do not forget to pin down the version\nFROM jupyterhub/jupyterhub:4.0.1\n\n# Install dependencies (for advanced authentication and spawning)\nRUN pip3 install \\\n    dockerspawner==12.1.0 \\\n    oauthenticator==14.2.0 \\\n    jupyterhub-idle-culler==1.2.1 \\\n    psycopg2-binary==2.9.3\n\nRUN pip3 install PyJWT==2.3.0\n\n# Copy the custom authenticator\nCOPY my_azuread.py .\n\nRUN mv my_azuread.py $(dirname "$(python3 -c "import oauthenticator as _; print(_.__file__)")")/my_azuread.py\n\n# Copy the JupyterHub configuration into the container\nCOPY jupyterhub_config.py .\n\n# Copy the POST_DEPLOY_SCRIPT into the container\nCOPY POST_DEPLOY_SCRIPT .\n\n# Copy the notebook dockerfile into the container\nCOPY images ./images\n')),(0,a.kt)("h3",{id:""}),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("code",null,"./jupyterhub_config.py")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"import os\nimport sys\nfrom pathlib import Path\nimport shutil\nfrom oauthenticator.my_azuread import MyAzureAdOAuthenticator\nfrom dockerspawner import DockerSpawner\n\nPREFIX = 'jupyter'\nADMINS = set(['foo-bar--mail-ch'])\nHOME_PATH = '/home/jovyan/work'\nAPP_NAME = f'{PREFIX}-jupyterhub'\nAPP_ROOT_HOST = f'/var/lib/dokku/data/storage/{APP_NAME}'\n\nVOLUME_GROUPS = {\n    'data-science': [\n        f'{APP_ROOT_HOST}/groups/data-science'\n    ]\n}\n\nMEMBERSHIPS = {\n    'foo-bar--mail-ch': set(['data-science'])\n}\n\nPERFORMANCE_LIMITS = {\n    'foo-bar--mail-ch': '8G'\n}\n\n\nclass MyDockerSpawner(DockerSpawner):\n\n    def start(self):\n        username = self.user.name\n        if self.user.name in ADMINS:\n            shared_mode = 'rw'\n        else:\n            shared_mode = 'ro'\n        root = Path(notebook_dir)\n        # basic volumes\n        self.volumes = {\n            f'{APP_ROOT_HOST}/data/users/{username}': {'bind': notebook_dir, 'mode': 'rw'},\n            f'{APP_ROOT_HOST}/data/user-settings/{username}': {'bind': '/home/jovyan/.jupyter/lab', 'mode': 'rw'},\n            f'{APP_ROOT_HOST}/data/shared': {'bind': str(root.joinpath('shared')), 'mode': shared_mode},\n            f'{APP_ROOT_HOST}/data/colab': {'bind': str(root.joinpath('colab')), 'mode': 'rw'}\n        }\n\n        # additional volumes for assigned students only\n        if self.user.name in MEMBERSHIPS:\n            for group in MEMBERSHIPS[self.user.name]:\n                for group_dir in VOLUME_GROUPS[group]:\n                    # make a relative path to mount, e.g.\n                    #   /var/lib/dokku/data/storage/jupyterhub/groups/data-science/\n                    # will be mounted to\n                    #   /groups/data-science/\n                    parts = Path(group_dir).relative_to(APP_ROOT_HOST).parts\n\n                    self.volumes[group_dir] = {\n                        'bind': str(root.joinpath(*parts)),\n                        'mode': shared_mode\n                    }\n\n        if self.user.name in ADMINS:\n            self.volumes[f'{APP_ROOT_HOST}/data/users'] = {\n                'bind': str(root.joinpath('users')),\n                'mode': 'rw'\n            }\n\n        if self.user.name in PERFORMANCE_LIMITS:\n            self.extra_host_config = {\n                'mem_limit': PERFORMANCE_LIMITS[self.user.name],\n                'memswap_limit': '-1'\n            }\n        return super().start()\n\n\nc.JupyterHub.spawner_class = MyDockerSpawner\nc.JupyterHub.last_activity_interval = 150\nc.JupyterHub.shutdown_on_logout = True\n\n# Spawn containers from this image\nc.DockerSpawner.image = os.environ['DOCKER_JUPYTER_IMAGE']\n\n# JupyterHub requires a single-user instance of the Notebook server, so we\n# default to using the `start-singleuser.sh` script included in the\n# jupyter/docker-stacks *-notebook images as the Docker run command when\n# spawning containers.  Optionally, you can override the Docker run command\n# using the DOCKER_SPAWN_CMD environment variable.\n# spawn_cmd = os.environ.get('DOCKER_SPAWN_CMD', \"start-singleuser.sh\")\n# c.DockerSpawner.extra_create_kwargs.update({'command': spawn_cmd})\n\nc.DockerSpawner.network_name = os.environ['DOCKER_NETWORK_NAME']\nc.DockerSpawner.use_internal_ip = True\n\n# Pass the network name as argument to spawned containers\nc.DockerSpawner.extra_host_config = {'network_mode': os.environ['DOCKER_NETWORK_NAME']}\n\n\ndef ensure_dir(dir_path):\n    if not dir_path.exists():\n        dir_path.mkdir(exist_ok=True)\n    if dir_path.group() != 'users':\n        shutil.chown(str(dir_path), user=1000, group=100)\n\n\ndef set_user_permission(spawner):\n    '''ensures the correct access rights for the jupyterhub user group'''\n    username = spawner.user.name\n    container_data = os.environ.get('DATA_VOLUME_CONTAINER', '/data')\n    data_root = Path(container_data, 'users')\n    ensure_dir(data_root)\n    ensure_dir(data_root.joinpath(username))\n    settings_root = Path(container_data, 'user-settings')\n    ensure_dir(settings_root)\n    ensure_dir(settings_root.joinpath(username))\n\n\nc.Spawner.pre_spawn_hook = set_user_permission\n\n# Explicitly set notebook directory because we'll be mounting a host volume to\n# it.  Most jupyter/docker-stacks *-notebook images run the Notebook server as\n# user `jovyan`, and set the notebook directory to `/home/jovyan/work`.\n# We follow the same convention.\n\n\nnotebook_dir = os.environ.get('DOCKER_NOTEBOOK_DIR') or HOME_PATH\nc.DockerSpawner.notebook_dir = notebook_dir\n# Mount the real user's Docker volume on the host to the notebook user's\n# notebook directory in the container\n\nc.DockerSpawner.extra_host_config = {\n    'mem_limit': '350m',\n    'memswap_limit': '-1'\n}\n#    'mem_swappiness': 0\n\n\n# Remove containers once they are stopped\nc.DockerSpawner.remove_containers = True\nc.DockerSpawner.name_template = f'{PREFIX}{\"-{prefix}-{username}\"}'\n# For debugging arguments passed to spawned containers\nc.DockerSpawner.debug = False\n\n# c.JupyterHub.bind_url = 'http://127.0.0.1:8000'\n\nc.JupyterHub.hub_ip = '0.0.0.0'\nc.JupyterHub.hub_connect_ip = os.environ['HUB_IP']\nc.JupyterHub.services = [\n    {\n        'name': 'idle-culler',\n        'admin': True,\n        'command': [\n            sys.executable,\n            '-m',\n            'jupyterhub_idle_culler',\n            '--timeout=300'\n        ],\n    }\n]\n\n\n# Authenticate users with GitHub OAuth\n# c.JupyterHub.authenticator_class = 'oauthenticator.GitHubOAuthenticator'\n# c.GitHubOAuthenticator.oauth_callback_url = os.environ['OAUTH_CALLBACK_URL']\nc.JupyterHub.authenticator_class = MyAzureAdOAuthenticator\nc.MyAzureAdOAuthenticator.tenant_id = os.environ.get('AAD_TENANT_ID')\nc.MyAzureAdOAuthenticator.oauth_callback_url = os.environ.get('AAD_OAUTH_CALLBACK_URL')\nc.MyAzureAdOAuthenticator.client_id = os.environ.get('AAD_CLIENT_ID')\nc.MyAzureAdOAuthenticator.client_secret = os.environ.get('AAD_CLIENT_SECRET')\n\n# Persist hub data on volume mounted inside container\ndata_dir = os.environ.get('DATA_VOLUME_CONTAINER', '/data')\nc.JupyterHub.cookie_secret_file = os.path.join(data_dir,\n                                               'jupyterhub_cookie_secret')\n\nc.JupyterHub.db_url = os.environ['DATABASE_URL']\n\n# Whitlelist users and admins\nc.Authenticator.admin_users = ADMINS\n\n# admin can access all other users\nc.JupyterHub.admin_access = True\n\nc.Spawner.default_url = '/lab'\n"))),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("code",null,"./my_azuread.py")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"\"\"\"\nCustom Authenticator to use Azure AD with JupyterHub\n\n\"\"\"\"\"\"\nCustom Authenticator to use Azure AD with JupyterHub\n\n\"\"\"\nimport json\nimport jwt\nimport urllib\n# import logging\n# logging.basicConfig(filename='example_jwt.log', encoding='utf8', level=logging.DEBUG)\n\nfrom tornado.httpclient import HTTPRequest, AsyncHTTPClient\n\nfrom jupyterhub.auth import LocalAuthenticator\n\nfrom traitlets import default\nfrom .azuread import AzureAdOAuthenticator\n\n\ndef azure_token_url_for(tentant):\n    return 'https://login.microsoftonline.com/{0}/oauth2/token'.format(tentant)\n\n\ndef azure_authorize_url_for(tentant):\n    return 'https://login.microsoftonline.com/{0}/oauth2/authorize'.format(\n        tentant)\n\n\ndef sanitized_username(raw):\n    cleaned_name = raw.lower()\n    cleaned_name = cleaned_name.replace(',', '')\n    cleaned_name = cleaned_name.replace(' ', '')\n    cleaned_name = cleaned_name.replace('@', '--')\n    cleaned_name = cleaned_name.replace('.', '-')\n\n    if len(cleaned_name) > 31:\n        # we need to shorten this because it won't work with the system's useradd!\n        splitpos = cleaned_name.find(\"--\")\n        before = cleaned_name[0:splitpos]\n        after = cleaned_name[splitpos:]\n        remaining = 31 - len(after)\n        shortened = before[0:remaining]\n        cleaned_name = shortened + after\n    return cleaned_name\n\n\nclass MyAzureAdOAuthenticator(AzureAdOAuthenticator):\n    login_service = \"Office365 GBSL\"\n\n    @default('username_claim')\n    def _username_claim_default(self):\n        return 'unique_name'\n\n    def normalize_username(self, username):\n        \"\"\"\n        Override normalize_username to avoid lowercasing usernames\n        \"\"\"\n        return sanitized_username(username)\n\n    async def authenticate(self, handler, data=None):\n        code = handler.get_argument(\"code\")\n        http_client = AsyncHTTPClient()\n\n        params = dict(\n            client_id=self.client_id,\n            client_secret=self.client_secret,\n            grant_type='authorization_code',\n            code=code,\n            redirect_uri=self.get_callback_url(handler))\n\n        data = urllib.parse.urlencode(\n            params, doseq=True, encoding='utf-8', safe='=')\n\n        url = azure_token_url_for(self.tenant_id)\n\n        headers = {\n            'Content-Type':\n            'application/x-www-form-urlencoded; charset=UTF-8'\n        }\n        req = HTTPRequest(\n            url,\n            method=\"POST\",\n            headers=headers,\n            body=data  # Body is required for a POST...\n        )\n\n        resp = await http_client.fetch(req)\n        resp_json = json.loads(resp.body.decode('utf8', 'replace'))\n\n        # app_log.info(\"Response %s\", resp_json)\n        access_token = resp_json['access_token']\n\n        id_token = resp_json['id_token']\n        decoded = jwt.decode(id_token, options={\"verify_signature\": False})\n        cleaned_name = sanitized_username(decoded[self.username_claim])\n\n        userdict = {\"name\": cleaned_name}\n\n        userdict[\"auth_state\"] = auth_state = {}\n        auth_state['access_token'] = access_token\n        # results in a decoded JWT for the user data\n        auth_state['user'] = decoded\n\n        return userdict\n\n\nclass LocalMyAzureAdOAuthenticator(LocalAuthenticator, MyAzureAdOAuthenticator):\n    \"\"\"A version that mixes in local system user creation\"\"\"\n    pass\n\n"))),(0,a.kt)("h2",{id:"images"},"Images"),(0,a.kt)("p",null,"The runtime image must be available on the dokku server. It is possbible to build it after each deploy (postdeploy script) or to pull the image manually on the dokku host from a registry."),(0,a.kt)("h3",{id:"option-1-pull-an-existing-image"},"Option 1: Pull an existing image"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"remove or rename the ",(0,a.kt)("inlineCode",{parentName:"li"},"POST_DEPLOY_SCRIPT")," from the repository, otherwise it will be used to build the image... (",(0,a.kt)("inlineCode",{parentName:"li"},"mv POST_DEPLOY_SCRIPT _POST_DEPLOY_SCRIPT"),")"),(0,a.kt)("li",{parentName:"ol"},"pull the preferred image and configure your jupyterhub to use it:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-sh"},'docker pull jupyter/scipy-notebook:latest\n\n# and set the network as default\ndokku config:set $APP DOCKER_JUPYTER_IMAGE="jupyter/scipy-notebook:latest"\n')),(0,a.kt)("h3",{id:"option2-imagesdockerfile"},"Option2: ",(0,a.kt)("inlineCode",{parentName:"h3"},"./images/Dockerfile")),(0,a.kt)("p",null,"(ensure you have the ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/lebalz/dokku-post-deploy-script"},"post-deploy-script")," plugin installed on your dokku host)"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Configure a ",(0,a.kt)("inlineCode",{parentName:"p"},"DOCKER_JUPYTER_IMAGE")," on your host - this name will be used to tag your built image"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'dokku config:set $APP DOCKER_JUPYTER_IMAGE="jupyter/lebalz:latest"\n'))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Add a ",(0,a.kt)("inlineCode",{parentName:"p"},"POST_DEPLOY_SCRIPT")," to the root (already done here)."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'#!/bin/bash\n# create and tag image...\nTAG=$(dokku config:get $APP DOCKER_JUPYTER_IMAGE)\necho $TAG\necho "start build"\n(cd images && docker build . -t $TAG)\n'))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Setup your ",(0,a.kt)("inlineCode",{parentName:"p"},"images/Dockerfile")),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-docker"},' FROM jupyter/minimal-notebook:lab-4.0.2\n\n LABEL maintainer="dev-name"\n LABEL version="0.0.1"\n LABEL description="Jupyter Notebook image"\n\n USER root\n # graphviz and graphviz-dev is needed for use with jupyterlab\n RUN apt-get update -y && apt-get install -y graphviz graphviz-dev\n USER jovyan\n\n # all additional pip packages\n RUN pip3 install --no-cache \\\n     jupyterhub==4.0.1 \\\n     jupyterlab==4.0.2 \\\n     notebook==6.5.4 \\\n     numpy==1.25.0 \\\n     Pillow==10.0.0 \\\n     pandas==2.0.3 \\\n     xlrd==2.0.1 \\\n     openpyxl==3.1.2 \\\n     ipywidgets==8.0.7 \\\n     ipympl==0.9.3 \\\n     jupyterlab-spellchecker==0.8.3 \\\n     orjson==3.9.1\\\n     graphviz==0.20\n \n # add the overrides file to the jupyterlab image: \n COPY overrides.json /opt/conda/share/jupyter/lab/settings/\n'))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Make sure that all your Dependencies to build your image are configured properly on your dokku host under ",(0,a.kt)("inlineCode",{parentName:"p"},"DOKKU_POST_DEPLOY_SCRIPT_DEPENDENCIES")),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'dokku config:set --no-restart $APP DOKKU_POST_DEPLOY_SCRIPT_DEPENDENCIES="images/Dockerfile;images/overrides.json"\n')))),(0,a.kt)("h2",{id:"dokku-setup"},"Dokku Setup"),(0,a.kt)("p",null,"Expecting dokku service name is set via ",(0,a.kt)("inlineCode",{parentName:"p"},"APP")," Env, e.g. ",(0,a.kt)("inlineCode",{parentName:"p"},'APP="jupyterhub"')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'APP="jupyterhub"\nDOMAIN="your.domain.com"\n# create app\n############\n\ndokku apps:create $APP\n# ensure docker networks can be used\n# dokku version >= v26\ndokku scheduler:set $APP selected docker-local\n# for dokku dokku version < v26\n# dokku config:set $APP DOCKER_SCHEDULER=docker-local\n\n# configure port map for accessing hub\ndokku config:set $APP DOKKU_PROXY_PORT_MAP="http:80:8000"\n\n# mount docker socket to spawn new containers\ndokku storage:mount $APP /var/run/docker.sock:/var/run/docker.sock\n\n# add a domain to it\ndokku domains:add $APP $DOMAIN\n\n# create network\ndokku network:create $APP\ndokku network:set $APP bind-all-interfaces true\n\n# attach the network to the app\ndokku network:set $APP attach-post-create $APP\n\n# configure env variables for the network\ndokku config:set $APP DOCKER_NETWORK_NAME=$APP\ndokku config:set $APP HUB_IP=$APP.web\n\n# create postgres service\ndokku postgres:create $APP\ndokku postgres:link $APP $APP\n\n## The URI should start with postgresql:// instead of postgres://.\n#   SQLAlchemy used to accept both, but has removed support for the\n#   postgres name.\nDB_URL=$(dokku config:get $APP DATABASE_URL)\ndokku config:set --no-restart $APP DATABASE_URL="${DB_URL//postgres:\\/\\//postgresql:\\/\\/}"\n# or optional edit the env file directly\n# nano /home/dokku/$APP/ENV\n\n# configure post deploy script\n# all files needed for the image build must be configured here\n# ";" separated list of files (relative to the root of the app)\n# - images/Dockerfile      /* the dockerfile for the image build */\n# - images/overrides.json  /* configure jupyterlab settings */\n# - ...\ndokku config:set --no-restart $APP DOKKU_POST_DEPLOY_SCRIPT_DEPENDENCIES="images/Dockerfile;images/overrides.json"\n\n# STOARGE AND DATA PERSISTENCE\n##############################\n\nmkdir -p /var/lib/dokku/data/storage/$APP/data\ndokku storage:mount $APP /var/lib/dokku/data/storage/$APP/data:/data\n\n## create shared directories\nmkdir -p /var/lib/dokku/data/storage/$APP/data/shared\nmkdir -p /var/lib/dokku/data/storage/$APP/data/colab\n\n## grant user jovian:users access to shared mounted volumes\nchown -R 1000:100 /var/lib/dokku/data/storage/$APP/data/shared\nchown -R 1000:100 /var/lib/dokku/data/storage/$APP/data/colab\n\n# increase max body upload size\ndokku nginx:set $APP client-max-body-size 30m\n\n\n# AUTHENTICATORS - OAUTH\n########################\n### edit your credentials: `nano /home/dokku/$APP/ENV`\n# or use the dokku config:set command as shown below\n\n## GITHUB oauth config\n# dokku config:set $APP OAUTH_CALLBACK_URL="https://$DOMAIN/hub/oauth_callback"\n# dokku config:set $APP GITHUB_CLIENT_ID="XXXXXXXXXXXXXX"\n# dokku config:set $APP GITHUB_CLIENT_SECRET="XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"\n\n## AZURE AD oauth config\n# dokku config:set $APP AAD_TENANT_ID="xxxxxx-xxxxxx-xxxxxxx"\n# dokku config:set $APP AAD_OAUTH_CALLBACK_URL="https://$DOMAIN/hub/oauth_callback"\n# dokku config:set $APP AAD_CLIENT_ID="xxxxxx-xxxxxx-xxxxxxx"\n# dokku config:set $APP AAD_CLIENT_SECRET="xxxxxx-xxxxxx-xxxxxxx"\n\n')),(0,a.kt)("h3",{id:"letsencrypt"},"Letsencrypt"),(0,a.kt)("p",null,"After the initial deploy, you can enable letsencrypt for your domain."),(0,a.kt)("p",null,"Make sure:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"you have set a domain and your page is reachable"),(0,a.kt)("li",{parentName:"ul"},"no pagerules with permanent redirects e.g. from Cloudflare exists")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-sh"},'MAIL="your@email.address"\ndokku config:set --no-restart $APP DOKKU_LETSENCRYPT_EMAIL=$MAIL\ndokku letsencrypt $APP\n')),(0,a.kt)("h2",{id:"jupyterlab-settings"},"Jupyterlab Settings"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://jupyterlab.readthedocs.io/en/latest/user/directories.html"},"Jupyterlab Docs")),(0,a.kt)("p",null,"edit the ",(0,a.kt)("inlineCode",{parentName:"p"},"images/overrides.json")))}k.isMDXComponent=!0}}]);